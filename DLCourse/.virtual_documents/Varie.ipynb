


import numpy as np
import numba as nb
import matplotlib.pyplot as plt
import pandas as pd


url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'
column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',
                'Acceleration', 'Model Year', 'Origin']
raw_dataset = pd.read_csv(url, names=column_names,
                        na_values='?', comment='\t',
                        sep=' ', skipinitialspace=True)


raw_dataset.info()


raw_dataset.describe()


plt.hist(raw_dataset['Horsepower'])
plt.show()


raw_dataset.isna().sum()





raw_dataset.fillna(raw_dataset.median().iloc[0],inplace=True)


raw_dataset.describe()


data_cyl = raw_dataset[raw_dataset['Cylinders']==3]


data_cyl





import tensorflow as tf
from scipy.optimize import minimize


def tru_fun(x):
    return np.cos(1.5 * np.pi * x)


n_samples = 30
np.random.seed(0)
x = np.sort(np.random.rand(n_samples))
y = tru_fun(x) + np.random.rand(n_samples) * 0.1
x_test = np.linspace(0,1,100)


plt.figure()
degrees = [1,4,15]


def loss(p,func):
    ypred = func(list(p),x)
    return tf.reduce_mean(tf.square(ypred - y)).numpy()


for degree in degrees:
    res = minimize(loss, np.zeros(degree+1), args = (tf.math.polyval), method='BFGS')
    plt.plot(x_test, np.poly1d(res.x)(x_test), label=f'Poly degree={degree}')

plt.plot(x_test, tru_fun(x_test), label="True function")
plt.scatter(x, y, color='b', label="Samples")
plt.title("TensorFlow")
plt.xlabel("x")
plt.ylabel("y")
plt.xlim([0,1])
plt.ylim([-2,2])
plt.legend()

plt.show()





import tensorflow as tf


# fix random seed for tensorflow 
tf.random.set_seed(0)

# choose number of layers and nodes
n_input = 1
n_hidden1 = 5
n_hidden2 = 2
n_output = 1

#initial weights edges connecting nodes in the NN
weights = {
    'h1' : tf.Variable(tf.random.normal([n_input, n_hidden1])),
    'h2' : tf.Variable(tf.random.normal([n_hidden1,n_hidden2])),
    'out' : tf.Variable(tf.random.normal([n_hidden2,n_output]))
}

# random biases in the nodes
biases = {
    'b1' : tf.Variable(tf.random.normal([n_hidden1])),
    'b2' : tf.Variable(tf.random.normal([n_hidden2])),
    'out' : tf.Variable(tf.random.normal([n_output]))
}





def MLP(x):
    layer_1 = tf.sigmoid(tf.add(tf.matmul(x, weights['h1']), biases['b1']))
    layer_2 = tf.sigmoid(tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']))
    out_layer = tf.add(tf.matmul(layer_2, weights['out']), biases['out'])
    return out_layer


#print predictions 
x=np.linspace(-2,2,10, dtype=np.float32).reshape(-1,1)
y1 = MLP(x)
print(MLP(x))





model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(n_hidden1, activation='sigmoid', input_dim=1))
model.add(tf.keras.layers.Dense(n_hidden2, activation='sigmoid'))
model.add(tf.keras.layers.Dense(n_output, activation='linear'))
model.summary()


model.set_weights([weights['h1'], biases['b1'],
                   weights['h2'], biases['b2'],
                   weights['out'], biases['out']])


y2 = model.predict(x)


if not np.allclose(y1,y2):
    raise ValueError('Results do NOT match!')


type(model)





def create_baseline_model() -> "tf.keras.models.Sequential":
    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Dense(1, input_shape=(1,)))
    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), 
                  loss='mean_squared_error')
    return model


def create_nn_model() -> "tf.keras.models.Sequential":
    model = model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Dense(10, input_dim=1, activation = 'relu'))
    model.add(tf.keras.layers.Dense(10, activation = 'relu'))
    model.add(tf.keras.layers.Dense(10, activation = 'relu'))
    model.add(tf.keras.layers.Dense(1))
    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),
                 loss = 'mean_squared_error')
    return model
    


def plot_data(X,Y, color, title):
    plt.figure()
    plt.scatter(X,Y, c=color)
    plt.grid()
    plt.title(title)
    plt.xlabel('x')
    plt.ylabel('y')

def plot_history(history, title):
    plt.figure()
    plt.plot(history.epoch, 
             np.array( history.history['loss']), label='Train Loss')
    plt.plot(history.epoch, 
             np.array( history.history['val_loss']), label='Val Loss')
    plt.title(title)
    plt.xlabel('Epoch')
    plt.ylabel('Loss (MSE)')
    plt.legend()

def plot_results(X,Y, Y_predict, title):
    plt.figure()
    plt.scatter(X,Y, c='blue')
    plt.plot(X, Y_predict, color='red')
    plt.grid()
    plt.title(title)
    plt.xlabel('x')
    plt.ylabel('y')


data = np.loadtxt('https://raw.githubusercontent.com/scarrazza/DL2022/main/Lecture_4/data.dat')


X_train = data[:,0].reshape(-1,1)
Y_train = data[:,1].reshape(-1,1)

X_val = data[:,2].reshape(-1,1)
Y_val = data[:,3].reshape(-1,1)


plot_data(X_train,Y_train, 'blue', 'Training Data')
plot_data(X_train,Y_train, 'red', 'Validation Data')


model = create_baseline_model()
history = model.fit(X_train, Y_train, batch_size=X_train.shape[0],
                   epochs = 500,
                   validation_data=(X_val,Y_val))
plot_history(history, 'baseline')


model2 = create_nn_model()
history = model2.fit(X_train, Y_train, batch_size=X_train.shape[0], epochs=500, validation_data=(X_val, Y_val))
plot_history(history, "Neural Net")


plot_results(X_val, Y_val, model.predict(X_val), "Baseline")
plot_results(X_val, Y_val, model2.predict(X_val), "Neural Net")

plt.show()





(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()


def plot_sample(train_images, train_labels, class_names):
    plt.figure(figsize=(10,10))
    for i in range(25):
        plt.subplot(5,5,i+1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(train_images[i])
        plt.xlabel(class_names[train_labels[i][0]])
    plt.show()


class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

plot_sample(train_images, train_labels, class_names)


def plot_history(history):
    plt.figure()
    plt.plot(history.history['accuracy'], label='accuracy')
    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.ylim([0, 1])
    plt.legend(loc='lower right')


def create_model_flatten():
    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Rescaling(1./255, input_shape=(32, 32, 3)))
    model.add(tf.keras.layers.Flatten())
    model.add(tf.keras.layers.Dense(64, activation='relu'))
    model.add(tf.keras.layers.Dense(10, activation='softmax'))
    return model


def create_model_cnn():
    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Rescaling(1./255, input_shape=(32, 32, 3)))
    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))
    model.add(tf.keras.layers.MaxPooling2D((2, 2)))
    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(tf.keras.layers.MaxPooling2D((2, 2)))
    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(tf.keras.layers.Flatten())
    model.add(tf.keras.layers.Dense(64, activation='relu'))
    model.add(tf.keras.layers.Dense(10, activation='softmax'))
    return model


model1 = create_model_flatten()
model1.compile(optimizer='adam',
               loss='sparse_categorical_crossentropy',
               metrics=['accuracy'])
model1.summary()
history = model1.fit(train_images, train_labels, epochs=10,
                    validation_data=(test_images, test_labels))

test_loss, test_acc = model1.evaluate(test_images,  test_labels, verbose=2)
print(f"Test loss {test_loss} - test accuracy {test_acc}")
plot_history(history)

model2 = create_model_cnn()
model2.compile(optimizer='adam',
               loss='sparse_categorical_crossentropy',
               metrics=['accuracy'])
model2.summary()
history = model2.fit(train_images, train_labels, epochs=10,
                     validation_data=(test_images, test_labels))
test_loss, test_acc = model2.evaluate(test_images, test_labels, verbose=2)
print(f"Test loss {test_loss} - test accuracy {test_acc}")
plot_history(history)
plt.show()





import time


(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()


train_images = train_images.reshape(
    train_images.shape[0], 28, 28, 1).astype('float32')
# Normalize the images to [-1, 1]
train_images = (train_images - 127.5) / 127.5


BUFFER_SIZE = 60000
BATCH_SIZE = 256


# Batch and shuffle the data
train_dataset = tf.data.Dataset.from_tensor_slices(
    train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)


def make_generator_model():
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.Dense(
        7*7*256, use_bias=False, input_shape=(100,)))
    model.add(tf.keras.layers.BatchNormalization())
    model.add(tf.keras.layers.LeakyReLU())

    model.add(tf.keras.layers.Reshape((7, 7, 256)))
    model.add(tf.keras.layers.Conv2DTranspose(
        128, (5, 5), strides=(1, 1), padding='same', use_bias=False))

    model.add(tf.keras.layers.BatchNormalization())
    model.add(tf.keras.layers.LeakyReLU())

    model.add(tf.keras.layers.Conv2DTranspose(
        64, (5, 5), strides=(2, 2), padding='same', use_bias=False))

    model.add(tf.keras.layers.BatchNormalization())
    model.add(tf.keras.layers.LeakyReLU())

    model.add(tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(
        2, 2), padding='same', use_bias=False, activation='tanh'))

    return model


def make_discriminator_model():
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',
                                     input_shape=[28, 28, 1]))
    model.add(tf.keras.layers.LeakyReLU())
    model.add(tf.keras.layers.Dropout(0.3))

    model.add(tf.keras.layers.Conv2D(
        128, (5, 5), strides=(2, 2), padding='same'))
    model.add(tf.keras.layers.LeakyReLU())
    model.add(tf.keras.layers.Dropout(0.3))

    model.add(tf.keras.layers.Flatten())
    model.add(tf.keras.layers.Dense(1))

    return model


def generate_and_save_images(generator, discriminator, epoch, test_input):
    predictions = generator(test_input, training=False)
    decisions = discriminator(predictions)

    fig = plt.figure(figsize=(10, 10))
    for i in range(predictions.shape[0]):
        plt.subplot(5, 5, i+1)
        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')
        plt.title(f"{decisions.numpy()[i,0]:.2f}")
        plt.axis('off')
    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))




generator = make_generator_model()
discriminator = make_discriminator_model()
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)


def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss


def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)


generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)


EPOCHS = 50
noise_dim = 100
num_examples_to_generate = 25

# You will reuse this seed overtime
seed = tf.random.normal([num_examples_to_generate, noise_dim])


generate_and_save_images(generator, discriminator, -1, seed)


@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)

        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)

        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(
        gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(
        disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(
        zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(
        zip(gradients_of_discriminator, discriminator.trainable_variables))


def train(dataset, epochs):
    for epoch in range(epochs):
        start = time.time()

        for image_batch in dataset:
            train_step(image_batch)

        # Produce images for the GIF as you go
        generate_and_save_images(generator, discriminator,
                                 epoch + 1,
                                 seed)

        print('Time for epoch {} is {} sec'.format(
            epoch + 1, time.time()-start))
         
        # Generate after the final epoch
        generate_and_save_images(generator, discriminator,
                             epochs,
                             seed)


train(train_dataset, EPOCHS)



